{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"\\n\".join([\"\".join(['*' for _ in range(i + 1)]) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_pickle(\"model/soma_goods_train.df\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "from konlpy.tag import Twitter; t = Twitter()\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90985 인텔 인텔 코어i7-4세대 4770K (하스웰) (정품)\n"
     ]
    }
   ],
   "source": [
    "for each in train_df.iterrows():\n",
    "    print each[0], each[1]['name']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brackets = [\"[\", \"{\", \"(\"]\n",
    "brackete = [\"]\", \"}\", \")\"]\n",
    "def getBrac(name, chk=True):\n",
    "    brac = {True:\"\", False:\"\"}\n",
    "    for c in name:\n",
    "        chk = not c in brackets and chk\n",
    "        if c not in brackets and c not in brackete: brac[chk] += c\n",
    "        else: brac[chk] += \" \"; brac[not chk] += \" \"\n",
    "        chk = c in brackete or chk\n",
    "    return (brac[True], brac[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram_cnt = 2\n",
    "chk_NC = [\"NN\", \"CD\"]\n",
    "chk_NA = [\"Noun\"]\n",
    "chk_NAN = [\"Noun\", \"Number\"]\n",
    "\n",
    "getNLTK = lambda name, chk : [token[0] for token in pos_tag(name) if token[1][:2] in chk]\n",
    "getKONL = lambda name, chk : [token[0] for token in t.pos(name) if token[1] in chk]\n",
    "getTokn = lambda name, chk_ko, chk_en : [token[0] for token in t.pos(name) if (token[1] == \"Alpha\") or token[1] in chk_ko]\n",
    "getGram = lambda name, cnt : [\" \".join([\"\".join(grams)]) for grams in ngrams(name, cnt)]\n",
    "def getName(name):\n",
    "\tbrac = getBrac(name)\n",
    "\tnoun = getTokn(brac[0], chk_NAN, chk_NC) + getTokn(brac[1], chk_NAN, chk_NC)\n",
    "\tgram = getGram(noun, min(gram_cnt, max(len(noun)-1, 1)))\n",
    "\treturn \" \".join(list(set(noun)) + list(set(gram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imge_cnt = 3\n",
    "from classify_image_module import getImageJson\n",
    "def getImge(name):\n",
    "    return getImageJson(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print getImge(str(230280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = u\"[해외]Gustard ES9018 is DAC x12 DAC Decoder Xmos USB Support DSD XLR Balanced Output\"\n",
    "brac = getBrac(text)\n",
    "print \"brac: \", brac\n",
    "noun = getTokn(brac[0], chk_NAN, chk_NC) + getTokn(brac[1], chk_NA, chk_NC)\n",
    "print \"noun: \", noun\n",
    "gram = getGram(noun, min(gram_cnt, max(len(noun)-1, 1)))\n",
    "print \"gram: \", gram\n",
    "name = \" \".join(gram + noun) \n",
    "print \"name: \", name\n",
    "print \"getN: \", getName(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "getTokenize = lambda name : list(set([token[0] for token in t.pos(name)]))\n",
    "getNoun = lambda name : list(set([token[0] for token in t.pos(name) if token[1] in check_Twitter]))\n",
    "getName = lambda name : \" \".join(getTokenize(removeBracket(name))) + \" \" + \" \".join(getNoun(removeBracket(name))) +\" \" + \" \".join(getTokenize(getBrackets(name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = u\"델Dell 에일리언웨어 13 X54E501AKR [i5-4210U/8G/1TB/13.3형FHD/GTX860 2G]\"\n",
    "print getName(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for token in t.pos(name):\n",
    "    print token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"model/soma_goods_train.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from konlpy.tag import Mecab; mecab = Mecab()\n",
    "from konlpy.tag import Twitter; t = Twitter()\n",
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_nltk = [\"NN\", \"CD\"]\n",
    "check_Twitter = [\"Noun\", \"Alpha\", \"Number\"]\n",
    "#check_Mecab = [\"NNG\", \"MM\", \"NP\", \"SN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getNLTK = lambda name : \"%\".join([token for token in word_tokenize(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getNLTKTag = lambda name : \"%\".join([pos_tag(token)[0][1] for token in word_tokenize(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getKONLPY = lambda name : \"%\".join([token for token in t.morphs(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getKONLPYTag = lambda name : \"%\".join([pos_tag(token)[1] for token in t.morphs(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getName = lambda name : getKONLPY(getNLTK(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getNoun = lambda name : \" \".join([token[0] for token in t.pos(name) if token[1] in check_Twitter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge = lambda product : product[0] + \" \" + product[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getDict = lambda l : dict(zip(list(set(l)),range(len(set(l)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cated = [[], [], []]\n",
    "cates = []\n",
    "names = []\n",
    "named = []\n",
    "for each in train_df.iterrows():\n",
    "    cated[0].append(each[1]['cate1'])\n",
    "    cated[1].append(each[1]['cate2'])\n",
    "    cated[2].append(each[1]['cate3'])\n",
    "    cates.append(\" \".join([each[1]['cate1'],each[1]['cate2'],each[1]['cate3']]))\n",
    "    names.append(each[1]['name'])\n",
    "    named.append(getNoun(each[1]['name']))\n",
    "cates_dict = getDict(cates)\n",
    "cated_dict = [getDict(d) for d in cated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_list_ = vectorizer.fit_transform(named)\n",
    "name_list = [[(i,d) for i, d in zip(l.indices, l.data)] for l in name_list_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = [(name, cate.split(\" \")) for (name, cate) in zip(named, cates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCount = lambda l : {i: l.count(i) for i in l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_size = 10000\n",
    "test_text_dic = {}\n",
    "test_cate_dic = {}\n",
    "test_products = products[:test_size]\n",
    "#test_cate_dic = getCount(test_cated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_products[0][0], test_products[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertText(text, cates, dic):\n",
    "    if text not in dic:\n",
    "        dic[text] = [{},{},{}]\n",
    "    for i in range(3):\n",
    "        if cates[i] not in dic[text][i]:\n",
    "            dic[text][i][cates[i]] = 0\n",
    "        dic[text][i][cates[i]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertCate(cate, text, dic):\n",
    "    if cate not in dic:\n",
    "        dic[cate] = {}\n",
    "    if text not in dic[cate]:\n",
    "        dic[cate][text] = 1\n",
    "    dic[cate][text]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dicfy(names, cates):\n",
    "    for name in list(set(names.split(\" \"))):\n",
    "        for cate in cates:\n",
    "            insertCate(cate, name, test_cate_dic)\n",
    "        insertText(name, cates, test_text_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pro in test_products:\n",
    "    dicfy(pro[0], pro[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print test_text_dic[u\"해외\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getTupleList = lambda dic : [(k, v) for k, v in dic.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getPercent = lambda l, s : [(item[0], float(item[1])/s) for item in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getSorted = lambda tl : sorted(tl, key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in test_cate_dic:\n",
    "    sorted_list = getSorted(getTupleList(test_cate_dic[key]))\n",
    "    test_cate_dic[key] = getPercent(sorted_list, sum(item[1] for item in sorted_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in test_text_dic:\n",
    "    for i in range(3):\n",
    "        sorted_list = getSorted(getTupleList(test_text_dic[key][i]))\n",
    "        test_text_dic[key][i] = getPercent(sorted_list, sum(item[1] for item in sorted_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_raw = u\"넷기어 네트워크하드 ReadyNAS RN2120 + 16TB (4TB HDD x 4개)\"\n",
    "test = getNoun(test_raw)\n",
    "result_cate = [{}, {}, {}]\n",
    "for token in list(set(test.split(\" \"))):\n",
    "    for i in range(3):\n",
    "        cates = []\n",
    "        for cate in test_text_dic[token][i]:\n",
    "            if not cates or cates[-1][1]/2. < cate[1]:\n",
    "                cates.append(cate)\n",
    "        for cate in cates:\n",
    "            if cate[0] not in result_cate[i]:\n",
    "                result_cate[i][cate[0]] = 0\n",
    "            result_cate[i][cate[0]]+=cate[1]\n",
    "\n",
    "for i in range(3):\n",
    "    print getSorted(getTupleList(result_cate[i]))[0]\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = [(names[i], cates[i]) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print text.split(\" \")\n",
    "for each in pos_tag(text):\n",
    "    print each[0], each[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for each in train_df.iterrows():\n",
    "    i+=1\n",
    "    if (i > 10):\n",
    "        break\n",
    "    print each[1]['name']\n",
    "    print getNLTK(each[1]['name'])\n",
    "    print getNLTKTag(each[1]['name'])\n",
    "    print getKONLPY(each[1]['name'])\n",
    "    print getKONLPYTag(each[1]['name'])\n",
    "    print getName(each[1]['name'])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trunk = [[], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pro_100 = products[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = products[0]\n",
    "print test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_merge = merge(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_text = \"\\n\".join([merge(pro) for pro in pro_100])\n",
    "print test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter; t = Twitter()\n",
    "texts = [p[0] for p in t.pos(test_text) if p[1] == \"Noun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec([texts])\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.save('ko_word2vec.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_split = [p[0] for p in t.pos(test_merge) if p[1] == \"Noun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print text_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print\n",
    "result = model.most_similar(positive=text_split, topn=20)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for res in result:\n",
    "    print res[0]\n",
    "    if res[0] in test[1].split(\" \"):\n",
    "        print res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for each in  test[1].split(\" \"):\n",
    "    print each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
